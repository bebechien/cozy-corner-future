<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>EmbeddingGemma on すみっコの未来</title><link>https://bebechien.github.io/cozy-corner-future/ja/tags/embeddinggemma/</link><description>Recent content in EmbeddingGemma on すみっコの未来</description><generator>Hugo</generator><language>ja</language><lastBuildDate>Mon, 19 Jan 2026 00:00:00 +0000</lastBuildDate><atom:link href="https://bebechien.github.io/cozy-corner-future/ja/tags/embeddinggemma/index.xml" rel="self" type="application/rss+xml"/><item><title>超軽量AIで、自分好みの記事だけが届くフィードをDIYした話。（皆さんもできます！）</title><link>https://bebechien.github.io/cozy-corner-future/ja/posts/embeddinggemma-tuning-lab/</link><pubDate>Mon, 19 Jan 2026 00:00:00 +0000</pubDate><guid>https://bebechien.github.io/cozy-corner-future/ja/posts/embeddinggemma-tuning-lab/</guid><description>&lt;h1 id="正直ノイズが多すぎませんか"&gt;正直、ノイズが多すぎませんか？&lt;/h1&gt;
&lt;p&gt;AI関連のニュースを追いかけるのは本当に大変です。「技術っぽくて面白そう」なタイトルを斜め読みするのに膨大な時間を費やしても、結局自分が求めている情報とは全然違ったりしますし…。キーワードフィルターも便利ですが、微妙なニュアンスまでは拾ってくれません。&lt;/p&gt;
&lt;p&gt;僕が欲しかったのは、単なる正規表現の文字列ではなく、「雰囲気」でニュースをフィルタリングする方法でした。&lt;/p&gt;
&lt;p&gt;そこで最近、&lt;strong&gt;EmbeddingGemma Tuning Lab&lt;/strong&gt; というツールで遊んでいます。これは、Googleの &lt;code&gt;embeddinggemma-300m&lt;/code&gt; モデルをファインチューニングして、自分だけの好みを理解させる新しい Hugging Face Space です。&lt;/p&gt;
&lt;h1 id="バイブスチェック-the-vibe-check"&gt;バイブス・チェック (The Vibe Check)&lt;/h1&gt;
&lt;p&gt;このプロジェクトの一番の魅力は、巨大なLLMのプロンプト戦略に頼っていないところです。代わりに &lt;strong&gt;&lt;a href="https://huggingface.co/collections/google/embeddinggemma"&gt;EmbeddingGemma&lt;/a&gt;&lt;/strong&gt; という、3億（300M）パラメータの軽量モデルを使用しています。これは埋め込み（Embedding）モデルなので、テキストをベクトルに変換してくれます。モデルの仕組みやトレーニング方法について詳しく知りたい方は、&lt;a href="https://developers.googleblog.com/ja/gemma-explained-embeddinggemma-architecture-and-recipe/"&gt;僕のブログ記事&lt;/a&gt;をチェックしてみてください。&lt;/p&gt;
&lt;p&gt;核心となるアイデアはユニークですが効果的です。このシステムは、&lt;code&gt;MY_FAVORITE_NEWS&lt;/code&gt;（私のお気に入りのニュース）というハードコードされたアンカーフレーズに対する「意味的類似度（Semantic Similarity）」のスコアに基づいています。&lt;/p&gt;
&lt;p&gt;デフォルトの状態では、モデルはそのフレーズが何を意味するのか知りません。しかし、ファインチューニングを行うことで、モデルが認識する世界を少しだけ歪めることができます。あなたが &lt;em&gt;実際に&lt;/em&gt; 好きな記事はその魔法のフレーズに数学的に近づき、嫌いな記事は遠ざけられるようになるのです。&lt;/p&gt;
&lt;h1 id="embeddinggemma-tuning-lab-3つの実行モード"&gt;「EmbeddingGemma Tuning Lab」: 3つの実行モード&lt;/h1&gt;
&lt;p&gt;EmbeddingGemma Tuning Lab は単なるトレーニングスクリプトではありません。実験スタイルに合わせて選べる3つの異なるアプリが含まれています。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;トレーナー (Gradio):&lt;/strong&gt; ここで魔法がかかります。Gradioアプリを立ち上げると、現在の &lt;a href="https://news.ycombinator.com/"&gt;Hacker News&lt;/a&gt; のトップ10ストーリーが表示されるので、気に入ったものにチェックを入れるだけ。「Fine-Tune」をクリックすると、裏側で &lt;a href="https://sbert.net/docs/package_reference/sentence_transformer/losses.html#multiplenegativesrankingloss"&gt;MultipleNegativesRankingLoss&lt;/a&gt; を使ってモデルが更新されます。検索結果がリアルタイムで自分の好みにシフトしていく様子を見るのは結構楽しいですよ。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ターミナルビューワー (CLI):&lt;/strong&gt; 真のターミナル愛好家のためのツールです。ライブフィードをスクロールできるインタラクティブなCLIアプリで、モデルのスコアに基づいて記事が色分けされます。「良いバイブス」なら緑、スキップなら赤といった具合です。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ウェブビューワー (Flask):&lt;/strong&gt; モデルの仕上がりに満足したら、軽量な Flask アプリを使ってみましょう。ローカルサーバー上でスタンドアロンの「ムードリーダー」としてデプロイすれば、自分だけのパーソナライズされたフィードをバックグラウンドで流しておけます。&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id="試してみてください"&gt;試してみてください&lt;/h1&gt;
&lt;p&gt;ニュースの無限スクロールをやめて、ニュースの「バイブスチェック」を始めたいなら、ぜひこのSpaceをチェックするかコードを入手してください。データの取得、トレーニングループ、可視化まで全部やってくれます。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Spaceをチェック:&lt;/strong&gt; &lt;a href="https://huggingface.co/spaces/google/embeddinggemma-tuning-lab"&gt;EmbeddingGemma Tuning Lab&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;コードを見る:&lt;/strong&gt; &lt;a href="https://huggingface.co/spaces/google/embeddinggemma-tuning-lab/tree/main"&gt;リポジトリ&lt;/a&gt;には、データセットのエクスポートや、ファインチューニング済みモデルをZIPでダウンロードするために必要なものがすべて揃っています。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;それでは、良いチューニングライフを！&lt;/p&gt;</description></item></channel></rss>