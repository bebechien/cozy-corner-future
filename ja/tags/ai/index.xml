<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI on すみっコの未来</title><link>https://bebechien.github.io/cozy-corner-future/ja/tags/ai/</link><description>Recent content in AI on すみっコの未来</description><generator>Hugo</generator><language>ja</language><lastBuildDate>Mon, 19 Jan 2026 00:00:00 +0000</lastBuildDate><atom:link href="https://bebechien.github.io/cozy-corner-future/ja/tags/ai/index.xml" rel="self" type="application/rss+xml"/><item><title>超軽量AIで、自分好みの記事だけが届くフィードをDIYした話。（皆さんもできます！）</title><link>https://bebechien.github.io/cozy-corner-future/ja/posts/embeddinggemma-tuning-lab/</link><pubDate>Mon, 19 Jan 2026 00:00:00 +0000</pubDate><guid>https://bebechien.github.io/cozy-corner-future/ja/posts/embeddinggemma-tuning-lab/</guid><description>&lt;h1 id="正直ノイズが多すぎませんか"&gt;正直、ノイズが多すぎませんか？&lt;/h1&gt;
&lt;p&gt;AI関連のニュースを追いかけるのは本当に大変です。「技術っぽくて面白そう」なタイトルを斜め読みするのに膨大な時間を費やしても、結局自分が求めている情報とは全然違ったりしますし…。キーワードフィルターも便利ですが、微妙なニュアンスまでは拾ってくれません。&lt;/p&gt;
&lt;p&gt;僕が欲しかったのは、単なる正規表現の文字列ではなく、「雰囲気」でニュースをフィルタリングする方法でした。&lt;/p&gt;
&lt;p&gt;そこで最近、&lt;strong&gt;EmbeddingGemma Tuning Lab&lt;/strong&gt; というツールで遊んでいます。これは、Googleの &lt;code&gt;embeddinggemma-300m&lt;/code&gt; モデルをファインチューニングして、自分だけの好みを理解させる新しい Hugging Face Space です。&lt;/p&gt;
&lt;h1 id="バイブスチェック-the-vibe-check"&gt;バイブス・チェック (The Vibe Check)&lt;/h1&gt;
&lt;p&gt;このプロジェクトの一番の魅力は、巨大なLLMのプロンプト戦略に頼っていないところです。代わりに &lt;strong&gt;&lt;a href="https://huggingface.co/collections/google/embeddinggemma"&gt;EmbeddingGemma&lt;/a&gt;&lt;/strong&gt; という、3億（300M）パラメータの軽量モデルを使用しています。これは埋め込み（Embedding）モデルなので、テキストをベクトルに変換してくれます。モデルの仕組みやトレーニング方法について詳しく知りたい方は、&lt;a href="https://developers.googleblog.com/ja/gemma-explained-embeddinggemma-architecture-and-recipe/"&gt;僕のブログ記事&lt;/a&gt;をチェックしてみてください。&lt;/p&gt;
&lt;p&gt;核心となるアイデアはユニークですが効果的です。このシステムは、&lt;code&gt;MY_FAVORITE_NEWS&lt;/code&gt;（私のお気に入りのニュース）というハードコードされたアンカーフレーズに対する「意味的類似度（Semantic Similarity）」のスコアに基づいています。&lt;/p&gt;
&lt;p&gt;デフォルトの状態では、モデルはそのフレーズが何を意味するのか知りません。しかし、ファインチューニングを行うことで、モデルが認識する世界を少しだけ歪めることができます。あなたが &lt;em&gt;実際に&lt;/em&gt; 好きな記事はその魔法のフレーズに数学的に近づき、嫌いな記事は遠ざけられるようになるのです。&lt;/p&gt;
&lt;h1 id="embeddinggemma-tuning-lab-3つの実行モード"&gt;「EmbeddingGemma Tuning Lab」: 3つの実行モード&lt;/h1&gt;
&lt;p&gt;EmbeddingGemma Tuning Lab は単なるトレーニングスクリプトではありません。実験スタイルに合わせて選べる3つの異なるアプリが含まれています。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;トレーナー (Gradio):&lt;/strong&gt; ここで魔法がかかります。Gradioアプリを立ち上げると、現在の &lt;a href="https://news.ycombinator.com/"&gt;Hacker News&lt;/a&gt; のトップ10ストーリーが表示されるので、気に入ったものにチェックを入れるだけ。「Fine-Tune」をクリックすると、裏側で &lt;a href="https://sbert.net/docs/package_reference/sentence_transformer/losses.html#multiplenegativesrankingloss"&gt;MultipleNegativesRankingLoss&lt;/a&gt; を使ってモデルが更新されます。検索結果がリアルタイムで自分の好みにシフトしていく様子を見るのは結構楽しいですよ。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ターミナルビューワー (CLI):&lt;/strong&gt; 真のターミナル愛好家のためのツールです。ライブフィードをスクロールできるインタラクティブなCLIアプリで、モデルのスコアに基づいて記事が色分けされます。「良いバイブス」なら緑、スキップなら赤といった具合です。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ウェブビューワー (Flask):&lt;/strong&gt; モデルの仕上がりに満足したら、軽量な Flask アプリを使ってみましょう。ローカルサーバー上でスタンドアロンの「ムードリーダー」としてデプロイすれば、自分だけのパーソナライズされたフィードをバックグラウンドで流しておけます。&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id="試してみてください"&gt;試してみてください&lt;/h1&gt;
&lt;p&gt;ニュースの無限スクロールをやめて、ニュースの「バイブスチェック」を始めたいなら、ぜひこのSpaceをチェックするかコードを入手してください。データの取得、トレーニングループ、可視化まで全部やってくれます。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Spaceをチェック:&lt;/strong&gt; &lt;a href="https://huggingface.co/spaces/google/embeddinggemma-tuning-lab"&gt;EmbeddingGemma Tuning Lab&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;コードを見る:&lt;/strong&gt; &lt;a href="https://huggingface.co/spaces/google/embeddinggemma-tuning-lab/tree/main"&gt;リポジトリ&lt;/a&gt;には、データセットのエクスポートや、ファインチューニング済みモデルをZIPでダウンロードするために必要なものがすべて揃っています。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;それでは、良いチューニングライフを！&lt;/p&gt;</description></item><item><title>AI時代、それでも「つくる喜び」について</title><link>https://bebechien.github.io/cozy-corner-future/ja/posts/hello/</link><pubDate>Sun, 18 Jan 2026 00:00:00 +0000</pubDate><guid>https://bebechien.github.io/cozy-corner-future/ja/posts/hello/</guid><description>&lt;h1 id="機械の方が速くできるとしてもそれでも私たちがつくる理由"&gt;機械の方が速くできるとしても、それでも私たちが「つくる」理由。&lt;/h1&gt;
&lt;p&gt;私は文章を書き連ねることが好きです。特に、難しくて複雑な概念を、誰にでも分かるように柔らかく噛み砕いて説明できた時に喜びを感じます。&lt;/p&gt;
&lt;p&gt;絵を描くことも楽しみの一つです。いわゆる「エンジニアの絵」レベルのアマチュアな腕前ですが、百の言葉よりも一枚のすっきりとしたダイアグラムの方が、はるかに強力だと信じているからです。&lt;/p&gt;
&lt;p&gt;そして何より、私はコーディングを愛しています。自分の指先から、実際に動く何かが生み出されるそのプロセスが本当に好きなのです。&lt;/p&gt;
&lt;p&gt;生成AIという巨大な波に足を浸したのは2023年、Stable Diffusionが流行し始めた頃でした。それ以前からゲームAIの分野を覗き見してはいましたが、今振り返ってみると、あの時に始まった変化がITエコシステム全体を根底から揺るがしているように思えます。&lt;/p&gt;
&lt;p&gt;当時、私は西洋の画風を中心に学習されたモデルたちに、妙な渇きを感じていました。そこで自ら&lt;a href="https://huggingface.co/datasets/bebechien/shinyunbok_xl"&gt;データセット&lt;/a&gt;を削り出し、朝鮮時代の画家・&lt;a href="https://ja.wikipedia.org/wiki/%E7%94%B3%E6%BD%A4%E7%A6%8F"&gt;申潤福（シン・ユンボク）&lt;/a&gt;の筆致を&lt;a href="https://civitai.com/user/bebechien"&gt;AIに教え込む楽しさ&lt;/a&gt;に、しばらくのめり込みました。&lt;/p&gt;
&lt;p&gt;しかしふと、あまりにも手軽に溢れ出るハイクオリティな画像たちを前に、自分自身が限りなくちっぽけに感じる時期が訪れました。その圧倒的な感覚の中で私を支えてくれたのは、「新しい画風を教え、方向性を定めること」は依然として人間の領分であるという事実でした。&lt;/p&gt;
&lt;p&gt;似たような無力感は、執筆においても訪れました。ChatGPTとGeminiへと進化するモデルたちを見ながら、AIの作文能力が私を遥かに追い越していく過程を目の当たりにしました。しかし結局のところ、何を書くかというテーマを決め、自分の名前で世に出る文章の重みに耐えながら最後のピリオドを打つのは「私」であるという点、その責任感だけはAIには奪えないのだと気づきました。&lt;/p&gt;
&lt;p&gt;コーディングとて同じでしょうか。まだ私が直接タイピングする比重は高いですが、新しいモデルが出るたびに、その進化の速度には開いた口が塞がりません。&lt;/p&gt;
&lt;p&gt;すでに文章や絵においては、私よりAIの方が上手（うわて）です。そのため、私が粗いドラフトを投げ、AIが滑らかに整え、私が最終的な検収と調整を行うという協業プロセスが日常に定着しました。モデルが賢くなればなるほど、私が手を加える部分は減り続けています。遠からず、コーディングもまたこのプロセスを辿ることになるだろうという予感がします。&lt;/p&gt;
&lt;p&gt;昨日参加した&lt;a href="https://luma.com/6iyf5pca"&gt;AIワークショップ&lt;/a&gt;で、誰かが私に重みのある質問を投げかけました。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;「未来において、人間は一体何をすべきなのでしょうか？」&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;今もそうですが、これからはより多くのことがAIによって自動化されていくでしょう。&lt;/p&gt;
&lt;p&gt;しかし、私のような人間は、依然として自らの手で何かを作りたいと願うはずです。たとえAIという強力なツールの力を借りたとしても、その創造の始点と意図は、依然として「人」にあるはずだからです。&lt;/p&gt;
&lt;p&gt;AIが自ら作りたくて生成したものと、人が意図を持って作ったものは明確に区別されるでしょうし、その価値もまた異なる基準で測られることになるでしょう。&lt;/p&gt;
&lt;p&gt;それはまるで、椅子が一つ必要な時に、私たちが取れる選択肢が多様であることと似ていないでしょうか？&lt;/p&gt;
&lt;p&gt;もちろん、お金を払って快適な完成品を買うこともできます。しかしある人はIKEAで部品を買ってきて自分で組み立てる過程そのものを楽しみ、ある人は道具を揃えて木材を裁断しゼロから作り上げ、またある人は本当に原初に立ち返り、手作業で木を削る苦労を自ら買って出ることもあります。&lt;/p&gt;
&lt;p&gt;今私たちが、工場で大量生産された既製品と、職人の手工芸品にそれぞれ異なる対価を支払っているように、未来の私たちも、単に結果物に含まれた「過程」と「価値」によって、互いに異なる意味を付与しながら生きていくことになる気がします。&lt;/p&gt;</description></item></channel></rss>